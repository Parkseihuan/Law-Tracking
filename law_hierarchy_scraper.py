#!/usr/bin/env python3
"""
ë²•ë ¹ ì²´ê³„ë„ ì›¹ í¬ë¡¤ë§
êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì—ì„œ ì‹¤ì œ ë²•ë ¹ ì²´ê³„ë„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘
"""

import os
import json
import time
import requests
from typing import Dict, List, Optional
from pathlib import Path
from bs4 import BeautifulSoup
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()


class LawHierarchyScraper:
    """ë²•ë ¹ ì²´ê³„ë„ í¬ë¡¤ëŸ¬"""

    def __init__(self, data_dir: str = "data"):
        self.base_url = "https://www.law.go.kr"
        self.data_dir = Path(data_dir)
        self.hierarchy_file = self.data_dir / "law_relationships.json"

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.data_dir.mkdir(exist_ok=True)

        # ë¸Œë¼ìš°ì € í—¤ë” ì„¤ì • (403 ë°©ì§€)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }

        # ì„¸ì…˜ ì‚¬ìš© (ì¿ í‚¤ ìœ ì§€)
        self.session = requests.Session()
        self.session.headers.update(self.headers)

        # ê¸°ì¡´ ê´€ê³„ ë°ì´í„° ë¡œë“œ
        self.relationships = self._load_relationships()

    def _load_relationships(self) -> Dict:
        """ì €ì¥ëœ ê´€ê³„ ë°ì´í„° ë¡œë“œ"""
        if self.hierarchy_file.exists():
            with open(self.hierarchy_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def _save_relationships(self):
        """ê´€ê³„ ë°ì´í„° ì €ì¥"""
        with open(self.hierarchy_file, 'w', encoding='utf-8') as f:
            json.dump(self.relationships, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ê´€ê³„ ë°ì´í„° ì €ì¥: {self.hierarchy_file}")

    def scrape_hierarchy(self, law_mst_seq: str, law_name: str = None) -> Optional[Dict]:
        """
        ë²•ë ¹ ì²´ê³„ë„ í¬ë¡¤ë§

        Args:
            law_mst_seq: ë²•ë ¹ì¼ë ¨ë²ˆí˜¸ (lsiSeq)
            law_name: ë²•ë ¹ëª… (ì„ íƒ)

        Returns:
            ë²•ë ¹ ê´€ê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        url = f"{self.base_url}/LSW//lsStmdInfoP.do"
        params = {
            'lsiSeq': law_mst_seq,
            'ancYnChk': '0'
        }

        print(f"\nğŸ” ë²•ë ¹ ì²´ê³„ë„ í¬ë¡¤ë§: {law_name or law_mst_seq}")
        print(f"   URL: {url}?lsiSeq={law_mst_seq}")

        try:
            # ìš”ì²­ ì „ ì ì‹œ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            time.sleep(1)

            response = self.session.get(url, params=params, timeout=10)

            if response.status_code == 200:
                return self._parse_hierarchy_page(response.text, law_name, law_mst_seq)
            else:
                print(f"   âŒ ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}")
                return None

        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            return None

    def _parse_hierarchy_page(self, html: str, law_name: str, law_mst_seq: str) -> Dict:
        """HTML íŒŒì‹±í•˜ì—¬ ë²•ë ¹ ê´€ê³„ ì¶”ì¶œ"""
        soup = BeautifulSoup(html, 'html.parser')

        result = {
            "ë²•ë ¹ëª…": law_name,
            "ë²•ë ¹ì¼ë ¨ë²ˆí˜¸": law_mst_seq,
            "ìˆ˜ì§‘ì¼ì‹œ": datetime.now().isoformat(),
            "ìƒìœ„ë²•ë ¹": [],
            "í•˜ìœ„ë²•ë ¹": [],
            "ê´€ë ¨ë²•ë ¹": []
        }

        # ì²´ê³„ë„ ì˜ì—­ ì°¾ê¸°
        # ì¼ë°˜ì ìœ¼ë¡œ <div class="law_tree">, <ul class="tree">, <div id="lawTree"> ë“±ì˜ êµ¬ì¡° ì‚¬ìš©

        # íŒ¨í„´ 1: law_tree í´ë˜ìŠ¤
        tree_area = soup.find('div', class_='law_tree')
        if not tree_area:
            # íŒ¨í„´ 2: tree í´ë˜ìŠ¤
            tree_area = soup.find('ul', class_='tree')
        if not tree_area:
            # íŒ¨í„´ 3: lawTree ID
            tree_area = soup.find('div', id='lawTree')
        if not tree_area:
            # íŒ¨í„´ 4: í…Œì´ë¸” êµ¬ì¡°
            tree_area = soup.find('table', class_='lawStmdTbl')

        if tree_area:
            # ë§í¬ ìš”ì†Œì—ì„œ ë²•ë ¹ëª… ì¶”ì¶œ
            links = tree_area.find_all('a')

            for link in links:
                related_law_name = link.get_text(strip=True)

                if not related_law_name or related_law_name == law_name:
                    continue

                # ë§í¬ì—ì„œ lsiSeq ì¶”ì¶œ
                href = link.get('href', '')
                related_seq = None
                if 'lsiSeq=' in href:
                    try:
                        related_seq = href.split('lsiSeq=')[1].split('&')[0]
                    except:
                        pass

                # ê´€ê³„ ìœ í˜• íŒë‹¨ (ìƒìœ„/í•˜ìœ„/ê´€ë ¨)
                # ë¶€ëª¨ ìš”ì†Œì˜ í´ë˜ìŠ¤ë‚˜ í…ìŠ¤íŠ¸ë¡œ íŒë‹¨
                parent_li = link.find_parent('li')
                parent_div = link.find_parent('div')

                relation_type = "ê´€ë ¨ë²•ë ¹"  # ê¸°ë³¸ê°’

                # í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ìœ í˜• íŒë‹¨
                if parent_li:
                    class_names = parent_li.get('class', [])
                    if 'parent' in class_names or 'upper' in class_names:
                        relation_type = "ìƒìœ„ë²•ë ¹"
                    elif 'child' in class_names or 'lower' in class_names:
                        relation_type = "í•˜ìœ„ë²•ë ¹"

                # í…ìŠ¤íŠ¸ íŒ¨í„´ìœ¼ë¡œ ìœ í˜• íŒë‹¨
                if "ì‹œí–‰ë ¹" in related_law_name or "ì‹œí–‰ê·œì¹™" in related_law_name:
                    relation_type = "í•˜ìœ„ë²•ë ¹"
                elif related_law_name.endswith("ë²•") and law_name and (
                    law_name.startswith(related_law_name.replace("ë²•", "")) or
                    "ì‹œí–‰ë ¹" in law_name or "ì‹œí–‰ê·œì¹™" in law_name
                ):
                    relation_type = "ìƒìœ„ë²•ë ¹"

                # ê´€ê³„ ì •ë³´ ì €ì¥
                relation_info = {
                    "ë²•ë ¹ëª…": related_law_name,
                    "ë²•ë ¹ì¼ë ¨ë²ˆí˜¸": related_seq
                }

                if relation_type == "ìƒìœ„ë²•ë ¹":
                    result["ìƒìœ„ë²•ë ¹"].append(relation_info)
                elif relation_type == "í•˜ìœ„ë²•ë ¹":
                    result["í•˜ìœ„ë²•ë ¹"].append(relation_info)
                else:
                    result["ê´€ë ¨ë²•ë ¹"].append(relation_info)

            print(f"   âœ… ì¶”ì¶œ ì™„ë£Œ:")
            print(f"      ìƒìœ„ë²•ë ¹: {len(result['ìƒìœ„ë²•ë ¹'])}ê°œ")
            print(f"      í•˜ìœ„ë²•ë ¹: {len(result['í•˜ìœ„ë²•ë ¹'])}ê°œ")
            print(f"      ê´€ë ¨ë²•ë ¹: {len(result['ê´€ë ¨ë²•ë ¹'])}ê°œ")
        else:
            print(f"   âš ï¸  ì²´ê³„ë„ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return result

    def scrape_all_tracked_laws(self, tracked_laws: Dict):
        """
        ì¶”ì  ì¤‘ì¸ ëª¨ë“  ë²•ë ¹ì˜ ì²´ê³„ë„ í¬ë¡¤ë§

        Args:
            tracked_laws: law_tracker.pyì˜ tracked_laws ë”•ì…”ë„ˆë¦¬
        """
        print("\n" + "="*80)
        print("ğŸ•·ï¸  ë²•ë ¹ ì²´ê³„ë„ ì¼ê´„ í¬ë¡¤ë§ ì‹œì‘")
        print("="*80)

        total = len(tracked_laws)
        success_count = 0

        for i, (law_name, info) in enumerate(tracked_laws.items(), 1):
            print(f"\n[{i}/{total}] {law_name}")

            law_mst_seq = info.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸')
            if not law_mst_seq:
                print("   âš ï¸  ë²•ë ¹ì¼ë ¨ë²ˆí˜¸ ì—†ìŒ")
                continue

            # ì´ë¯¸ í¬ë¡¤ë§í•œ ê²½ìš° ìŠ¤í‚µ (ìµœê·¼ 7ì¼ ì´ë‚´)
            if law_name in self.relationships:
                collected_date = self.relationships[law_name].get('ìˆ˜ì§‘ì¼ì‹œ')
                if collected_date:
                    try:
                        collected_dt = datetime.fromisoformat(collected_date)
                        days_ago = (datetime.now() - collected_dt).days
                        if days_ago < 7:
                            print(f"   â­ï¸  ìµœê·¼ í¬ë¡¤ë§ë¨ ({days_ago}ì¼ ì „)")
                            success_count += 1
                            continue
                    except:
                        pass

            # í¬ë¡¤ë§ ì‹¤í–‰
            result = self.scrape_hierarchy(law_mst_seq, law_name)

            if result:
                self.relationships[law_name] = result
                success_count += 1

                # ì¤‘ê°„ ì €ì¥ (10ê°œë§ˆë‹¤)
                if i % 10 == 0:
                    self._save_relationships()

        # ìµœì¢… ì €ì¥
        self._save_relationships()

        print("\n" + "="*80)
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {success_count}/{total}ê°œ ì„±ê³µ")
        print("="*80)

    def get_all_relationships(self) -> Dict:
        """ì €ì¥ëœ ëª¨ë“  ê´€ê³„ ë°ì´í„° ë°˜í™˜"""
        return self.relationships

    def get_law_relationships(self, law_name: str) -> Optional[Dict]:
        """íŠ¹ì • ë²•ë ¹ì˜ ê´€ê³„ ë°ì´í„° ë°˜í™˜"""
        return self.relationships.get(law_name)


def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    scraper = LawHierarchyScraper()

    # í…ŒìŠ¤íŠ¸: ì‚¬ë¦½í•™êµë²• ì²´ê³„ë„ í¬ë¡¤ë§ (ì˜ˆì‹œ lsiSeq)
    # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” law_tracker.pyì˜ tracked_lawsì—ì„œ lsiSeqë¥¼ ê°€ì ¸ì˜´

    test_law = {
        "ë²•ë ¹ëª…": "ì‚¬ë¦½í•™êµë²•",
        "ë²•ë ¹ì¼ë ¨ë²ˆí˜¸": "000273"  # ì˜ˆì‹œ (ì‹¤ì œëŠ” law_trackerì—ì„œ ì¡°íšŒ)
    }

    result = scraper.scrape_hierarchy(
        test_law["ë²•ë ¹ì¼ë ¨ë²ˆí˜¸"],
        test_law["ë²•ë ¹ëª…"]
    )

    if result:
        print("\nğŸ“‹ í¬ë¡¤ë§ ê²°ê³¼:")
        print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
